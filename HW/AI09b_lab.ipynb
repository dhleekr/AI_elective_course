{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AI09b_lab.ipynb의 사본","provenance":[{"file_id":"1ME2_31JOzSct9ecn567NZkHcFrR-1Ls0","timestamp":1605682838339},{"file_id":"1Fa480rd5HTMPp7tTxZbp6bV6O1aFHgw_","timestamp":1590936731948},{"file_id":"1xABU8Eu5jgmu-fWvaeCOLKdErDt9jo4F","timestamp":1590919193523},{"file_id":"1YWdT5QYOzPGd4Yv0PjlVNBuJD8DeCc1A","timestamp":1574668208724}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Mq3nlbXA-Mjz"},"source":["# AI 09b Policy Gradient\n","---\n","\n","> 학번:\n",">\n","> 이름:\n","\n","Source: https://github.com/wikibook/pytorch-drl"]},{"cell_type":"markdown","metadata":{"id":"_L80Wp4C_Omg"},"source":["### Import packages\n","---"]},{"cell_type":"code","metadata":{"id":"JZxvpsbK_KPA"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bBlZo8V4qquO"},"source":["## 정책반복\n","---"]},{"cell_type":"code","metadata":{"id":"vDwabeleqWs8","colab":{"base_uri":"https://localhost:8080/","height":303},"executionInfo":{"status":"ok","timestamp":1574682790830,"user_tz":-540,"elapsed":1795,"user":{"displayName":"Eisung Sohn","photoUrl":"","userId":"14422686701909288962"}},"outputId":"63f13fad-a590-449b-a31e-78407ff393ff"},"source":["# 9b.1\n","\n","# 초기 상태의 미로 모습\n","\n","# 전체 그림의 크기 및 그림을 나타내는 변수 선언\n","fig = plt.figure(figsize=(5, 5))\n","ax = plt.gca()\n","\n","# 붉은 벽 그리기\n","plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n","plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n","plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n","plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n","\n","# 상태를 의미하는 문자열(S0~S8) 표시\n","plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n","plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n","plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n","plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n","plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n","plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n","plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n","plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n","plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n","plt.text(0.5, 2.3, 'START', ha='center')\n","plt.text(2.5, 0.3, 'GOAL', ha='center')\n","\n","# 그림을 그릴 범위 및 눈금 제거 설정\n","ax.set_xlim(0, 3)\n","ax.set_ylim(0, 3)\n","plt.tick_params(axis='both', which='both', bottom=False, top=False,\n","                labelbottom=False, right=False, left=False, labelleft=False)\n","\n","# S0에 녹색 원으로 현재 위치를 표시\n","line, = ax.plot([0.5], [2.5], marker=\"o\", color='g', markersize=60)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAASUAAAEeCAYAAADM2gMZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAarElEQVR4nO3de1SUdf4H8PczN24DwS8NYUjQWCX4\n5ZqgB7RfZrBJdegi6QZbiRSrP+3ySzp23HXb7bbHTPTo6q8jZ5VKy800FTvVyibhPQM1TbR0zRta\nIInKZWCG+f7+GOEnCDOIM/N8Z3i/zpnjYb7PPM9nvsG77/OdZ76PIoQAEZEsNGoXQER0NYYSEUmF\noUREUmEoEZFUGEpEJBWGEhFJReeosV+/fiImJsZDpRBRX1FRUXFeCNG/qzaHoRQTE4Py8nL3VEVE\nfZaiKCe7a+PpGxFJhaFERFJhKBGRVBhKRCQVhhIRSYWhRERSYSgRkVQYSkQkFYYSEUmFoUREUmEo\nEZFUGEpEJBWGEhFJxeEqATITQqDqchUqzlZgT9UelJ0sQ2VNJZqsTbDarGi1tUKr0UKn0SFAF4D4\n/vEYGz0Wo0yjkBiZCFOwCYqiqP02iKgTrwolm7Dhy+NfYsHuBdhxagesNiv0Wj3qW+phE7Zrtrfa\nrLDarDBbzdhxegd2ndkFo8GIltYW6DV6jBk4BjOTZyJ1cCo0CgeNRDLwilC60HQBK/atQMGuAlxu\nuYz6lvr2tiZrU4/3YxM2XGq+BAAww4wvjn2B7ae2I9gQjPyUfOTemYuwgDCX109EPac4uhllUlKS\nUHORtzOXzmBWySysP7IeGkWDRkuj244VqA+ETdgwIW4C3vrNW4gKiXLbsYj6OkVRKoQQSV21SXnO\nIoTA8n3LEbckDh8f+hhmq9mtgQQAjZZGmK1mrDm0BnFL4rB833Lw7sFEniddKFVdqsK498bhhc9f\nQIOlAVZh9ejxrcKKBksDXvj8BYx7bxyqLlV59PhEfZ1UoVS0vwhxS+Kw4/QONFgaVK2lwdKAHad3\nIG5pHIr2F6laC1FfIkUoCSHw4hcv4tnPnkW9pR5Wm2dHR92x2qyob6nHs589i5n/nMnTOSIPUD2U\nWm2tyNmQg8K9hW6fN+qtRksjllUsw5SNU9Bqa1W7HCKfpuolAUII5G7MxdrDa6UNpDaNlkZ8XPkx\nAKDo4SJeeEnkJqqOlGb+cybWHV4nfSC1aQum/M35apdC5LNUC6Wi/UUo3Fuo+oT29Wo7lePkN5F7\nqBJKVZeq8Pxnz3vNCKmzRksjnv/8eV4uQOQGHg8lIQSyP8mGudXs6UO7VLO1Gb/75Hf8RI7IxTwe\nSiv2r0DF2QppPvbvLYvNgvKz5TyNI3Ixj4bSmUtn2q/U9gUNlga88MULPI0jciGPhtKskllotjZ7\n8pBuZ7aaMatkltplEPkMj4XShaYLWH9kvce/y+ZuVpsVnxz5BBeaLqhdCpFP8Fgordi3wmcXUtMo\nGs4tEbmIR1LCJmwo2FXgtZcAONNoaUTBzoIuV78kouvjkVD68viXuNxy2fU7bgDwKYCFAF4H8DaA\n9wD8+0q7AFAKYD6ANwAUAah2fRkAcKnlErb8uMU9O5dITU0Npk+fjpiYGPj5+SE8PBypqakoKSkB\nAHzyyScYP348+vfvD0VR8NVXX6lbsA9w1OcWiwUvv/wyhg0bhqCgIERERCA7OxunTp1Su+xe88h3\n3xbsXtBhCVuX+QiABcDDAP4D9pA6AaBtQLYDwC4AjwC4GUAZgPcBPAfAz7Wl1LfUo2BXAdIGp7l2\nx5LJzMxEY2Mjli9fjtjYWFRXV6OsrAy1tbUAgIaGBowePRpPPPEEnnrqKZWr9Q2O+ryxsRF79+7F\nH//4RwwfPhwXL15Efn4+0tPTceDAAeh0XrHidQduXw5XCIGb5t7k+pFSE4C3ADwJ4LauDgygAMAo\nAHdfec4C+2jqPgBdLsR5Y0L8QlD3cp3Pflm3rq4OYWFhKCkpQVqa4/A9f/48+vfvj9LSUtxzzz2e\nKdAHXU+ft6msrERCQgIOHDiAO+64w80V9o6qy+FWXa6CxWZx/Y4NVx7fwx42nV0AUI+OgaUHEA3g\ntOvLAYCW1hacvXzWPTuXgNFohNFoRHFxMcxm774i31v0ps8vXbLfHCMszDtvguH2UKo4WwGD1uD6\nHWthPy07AGAugL8D+CeAM1fa284Wgzq9LuiqNhczaA2oOFfhnp1LQKfT4d1338WqVasQGhqKlJQU\nvPTSS/j666/VLs1nXW+ft7S0ID8/HxkZGYiK8s6bX7g9lPZU7XHPfBIAxAPIB5ANIBb2EdDfAWx1\nz+GcaWhpwJ6qPeoc3EMyMzNx9uxZbNq0Cffffz927tyJ5ORk/PWvf1W7NJ/V0z63Wq144oknUFdX\nh6Ii771Exe1zSnetuAs7Tu+4oX1cl40AvgUwHcASAHkATFe1fwAgEMCj7jn8XQPvwrYp29yzc0k9\n88wzeP/991FfXw+DwT4q5pySe3Xuc6vViqysLBw8eBBfffUVBgwYoHaJDqk6p1RZU+nuQ3TUH4AN\ngPHK499XtVkAnARwq/sO7/H3K4H4+HhYrVbOM3nQ1X1usVjw29/+FgcOHEBpaan0geSM2z8vvJ47\n2F6XRgBrANwJIBz2j/jPwn4ZwGAA/gCSAWwD0A/2SwK2wj457sYPJJosbnq/EqitrcXEiRORm5uL\nYcOGITg4GOXl5Zg3bx5SU1MREhKCX375BadOnUJdXR0A4NixYwgNDcWAAQO8/o9FDc76PDAwEI89\n9hi++eYbbNq0CYqi4KeffgIA3HTTTQgICFD5HVw/t4eS25YoMQCIAvA1gF8AWAGEwB44bZcAjIF9\ndPQZ7JcQRMF+CYGLr1G6mls+aZSE0WhEcnIyFi1ahGPHjqG5uRkmkwnZ2dmYM2cOAKC4uBhTpkxp\nf01eXh4A4M9//jP+8pe/qFG2V3PW52fOnMHGjRsBAImJiR1eW1RUhJycHBWqvjFun1PSvKqBQN9Z\nCE2BAtuf+XUTIkdUnVPSarTuPoRU+tr7JXI1t4eSTuN9l7nfCL1Gr3YJRF7N7aEUoPO+ibYbEaDv\nW++XyNXcHkrx/ePdfQip9LX3S+Rqbg+lsdFjfXZxt860ihZjo8eqXQaRV3N7WowyjYLRYHT3YaQQ\nZAjCKNMotcsg8mpuD6XEyES0tLa4+zBSaGltQWJEovMNiahbbg8lU7Cpz3wiZdAaEBkcqXYZRF7N\n7aGkKArGDBzj7sNIYfSto312gTciT/HIDPTM5Jk+P69kNBiRn5KvdhlEXs8jVzamDk5FsCH4+tdV\n2grgIADlyiMA9u+wtcD+hdzQK9s9CGAg7Gt0FwC4H8DIq/azEP//fbcA2JctMcB+kwHAvuibBvYl\nTQD7cifX2TMhfiG4d9C91/ciIrqGR0JJo2iQn5KPV756pee3WToN4AcAU2GvsgFAK+xfuv0RwE4A\nv+v0mkrYv3T7HTqGEgBMhn3VyVLYw+4hAP99pa0U9pDq5VlmoD4Q+Sn5febSByJ38thfUe6dudd3\nX7TLsI9c2mIzCPZAcuQg7DcFuATgYjfbRF1pdyGbsGHK8CnONyQipzwWSmEBYXg07lHolB4Ozm6D\nPVgWw35vtxNOtr8I+2lYFIAEAIe62e4YgLieldATOo0OE+ImICzAOxdpJ5KNR8835v1mHvx0PVzM\nyA/2U7cM2EdJHwPY52D772APIwD4T9hHTVd7D/b5pmNw6SJv/jp/zPvNPNftkKiP82goRYVEYdH9\nixCk73yLkW5oAAwCMA7AAwAOO9j2OwD7YZ/UXg3gZwC1V7VPBvA/AAbAPofkAkH6ICxKXwRTiMn5\nxkTUIx6fmc0dnoukyCTnS5qcR8dQ+QnATQ62bYH9ziYvXnn8F64dLWkBpMN+Y4Eezrd3R6/RY6Rp\nJOeSiFzM46GkKAo+mPAB/LX+jjdsAbAe9juS/C+AGgD3dLPtd7h2nuj2K893Fgz76ds3PS65S346\nP6x6dBUvliRyMbcvh9udov1FePazZ3t+iYBEAvWBWPLAEo6SiHpJ1eVwuzNl+BT8fsTvEagPdL6x\nRIL0QZiaOJWBROQmql7tt2D8Ajx2+2NeE0yB+kA8Fv8YCu4rULsUIp+laigpioIVD6/AxPiJ0gdT\noD4QE+MnYvlDyzmPRORGqn8vQqvRoujhIkxNnCptMAXqAzEtcRqKHi7i3UqI3Ez1UALsI6YF4xdg\nyQNLYDQYpbkDil6jh9FgxJIHlqBgfAFHSEQeIEUotZkyfAqOzDiCMbeO6fkFlm4SpA/C6FtH48iM\nI5zUJvIgqUIJAEwhJpROLsXi+xfbR009/a6ci+g0OhgNRiy+fzFKJ5fyam0iD5MulAD76Vzunbk4\nPOMwJiVMgr/OH4E69843BeoC4a/zx6T4STgy4why78zl6RqRCuSYvOlGVEgUPsj8ABeaLqBofxHm\n75yPyy2Xr3+xOAeMBiNCDCHIH52PKcOn8Nv+RCpT7Yru3rAJG7b8uAUFuwqw8/ROtLS2wKA1oL6l\nvkdrNWkUDYwGY/vrRt86Gvkp+bh30L1coI3Igxxd0S31SKkzjaJB2uA0pA1OgxACZy+fRcW5Cuyp\n2oOyk2WorKlEk6UJFpsFrbZWaDVa6DV6BOgDEN8/HmOjx2KUaRQSIxIRGRzJ0zMiCXlVKF1NURSY\nQkwwhZjw0NCH1C6HiFyE5yxEJBWGEhFJhaFERFJhKBGRVBhKRCQVhhIRSYWhRERSYSgRkVQYSkQk\nFYYSEUmFoUREUmEoEZFUGEpEJBWvXSXAJ3EpFfU4WFeMPIsjJSKSCkdKMuH/rT2Po1PpcKRERFJh\nKBGRVBhKRCQVhhIRSYWhRERSYSgRkVQYSkQkFYYSEUmFoUREUmEoEZFUGEpEJBWGEhFJhaFERFJh\nKBGRVBhKRCQVhhIRSYWhRERSYSgRkVQYSkQkFYYSEUmFoUREUmEoEZFUGEpEJBWGEhFJhaFERFJh\nKBGRVBhKRCQVhhIRSYWhRERSYSgRkVQYSkQkFYYSEUmFoUREUvHqUKqpqcH06dMRExMDPz8/hIeH\nIzU1FSUlJQCAP/3pT4iLi0NQUBDCwsKQmpqKnTt3qly1d3PW51ebOnUqFEXB/PnzVajUdzjr85yc\nHCiK0uGRnJysctW9p1O7gBuRmZmJxsZGLF++HLGxsaiurkZZWRlqa2sBAEOHDsXSpUsxaNAgNDU1\nYeHChUhPT8fRo0cRHh6ucvXeyVmft1m7di327NmDyMhIlSr1HT3p87S0NKxcubL9Z4PBoEapriGE\n6PaRmJgoZHXhwgUBQJSUlPT4NRcvXhQAxBdffOHGynxXT/v8xIkTIjIyUlRWVoro6Gjx9ttve6jC\nXgDsD0n1pM8nT54sHnzwQQ9WdeMAlItucsdrT9+MRiOMRiOKi4thNpudbt/S0oLCwkKEhIRg+PDh\nHqjQ9/Skz61WK7KysjBnzhzcfvvtHq7Q9/T093z79u245ZZbMGTIEOTl5aG6utqDVbpYd2klJB8p\nCSHE2rVrRVhYmPDz8xPJyckiPz9f7N69u8M2mzZtEkFBQUJRFBEZGSm+/vprlar1Dc76/A9/+IPI\nyMho/5kjpRvnrM9Xr14tNm7cKA4cOCCKi4vFsGHDREJCgjCbzSpW7RgcjJS8OpSEEKKpqUls3rxZ\nvPrqqyIlJUUAEG+++WZ7e319vTh69KjYtWuXyM3NFdHR0eLs2bMqVuz9uuvz0tJSERkZKaqrq9u3\nZSi5hrPf86tVVVUJnU4n1q1b5+Eqe86nQ6mzp59+Wuj1etHc3Nxle2xsrHjttdc8XJVva+vz2bNn\nC0VRhFarbX8AEBqNRphMJrXL7JqXhFJnzn7PY2JixNy5cz1cVc85CiWv/vStK/Hx8bBarTCbzV1+\nAmGz2dDc3KxCZb6rrc+nTZuG7OzsDm3jx49HVlYW8vLyVKrONzn6PT9//jyqqqoQERGhUnU3xmtD\nqba2FhMnTkRubi6GDRuG4OBglJeXY968eUhNTQUAzJkzBxkZGYiIiEBNTQ2WLl2KM2fOYNKkSSpX\n752c9fnAgQOveY1er8eAAQMwdOhQFSr2fs76XKPR4KWXXkJmZiYiIiJw4sQJzJ49G7fccgseffRR\ntcvvFa8NJaPRiOTkZCxatAjHjh1Dc3MzTCYTsrOzMWfOHOh0Ohw6dAgrVqxAbW0tbr75ZowcORJb\nt27FsGHD1C7fKznrc3I9Z32u1Wpx8OBBvP/++6irq0NERATGjRuHNWvWIDg4WO3ye0Wxn951LSkp\nSZSXl3uwHCIPUxT7vw7+Dsj1FEWpEEIkddXmtdcpEZFvYigRkVQYSkQkFYYSEUmFoUREUmEoEZFU\nGEpEJBWGEhFJhaFERFJhKBGRVBhKRCQVhhIRSYWhRERSYSgRkVQYSkQkFYYSEUmFoUREUmEoEZFU\nGEpEJBWGEhFJhaFERFJhKBGRVBhKRCQVhhIRSYWhRERSYSgRkVQYSkQkFYYSEUmFoUREUmEoEZFU\nGEpEJBWGEhFJhaFERFJhKBGRVBhKRCQVhhIRSYWhRERSYSgRkVQYSkQkFYYSEUmFoUREUmEoEZFU\nGEpEJBWd2gXQVRTF/q8Q6tbRF7X1PamOIyUikgpHStS3cVSqDgcjU46UiEgqDCUikgpDiYikwlAi\nIqkwlIhIKgwlIpIKQ4mIpMJQIiKpMJSISCoMJSKSCkOJiKTCUCIiqTCUiEgqDCUikgpDiYikwlAi\nIqkwlIhIKgwlIpIKQ4mIpMJQIiKpMJSISCoMJSKSCkOJiKTCUCIiqTCUiEgqDCUikgpDiYikwlAi\nIqkwlIhIKgwlIpIKQ4mIpMJQIiKpMJSISCoMJSKSileHUk1NDaZPn46YmBj4+fkhPDwcqampKCkp\nad/mhx9+wIQJExAaGorAwECMGDEChw8fVrFq7+aszxVF6fIxY8YMlSv3Xs76vL6+Hs899xyioqIQ\nEBCAoUOHYuHChSpX3Xs6tQu4EZmZmWhsbMTy5csRGxuL6upqlJWVoba2FgDw448/YsyYMXjqqaew\nZcsWhIaG4siRIzAajSpX7r2c9fm5c+c6bF9eXo6MjAxMmjRJjXJ9grM+nzlzJv71r39h5cqVGDRo\nELZu3Yq8vDz069cPTz75pMrV94IQottHYmKikNWFCxcEAFFSUtLtNllZWSI7O9uDVd0gwP6QVE/6\nvLNnnnlGDBkyxI1V+bae9HlCQoJ45ZVXOjx39913ixkzZri7vF4DUC66yR2vPX0zGo0wGo0oLi6G\n2Wy+pt1ms2HTpk2Ij49Heno6+vfvj5EjR+Kjjz5SoVrf4KzPO6uvr8c//vEP5OXleaA639STPr/r\nrruwadMmnD59GgCwc+dO7N+/H+np6Z4s1XW6Sysh+UhJCCHWrl0rwsLChJ+fn0hOThb5+fli9+7d\nQgghzp07JwCIwMBAUVBQIPbt2ycKCgqEVqsVn376qcqVd0PykZIQjvu8s2XLlgmDwSCqq6s9XKVv\ncdbnzc3NIicnRwAQOp1O6HQ68c4776hYsXNwMFLy6lASQoimpiaxefNm8eqrr4qUlBQBQLz55pui\nqqpKABBZWVkdts/KyhLp6ekqVeuEF4SSEN33eWdJSUli4sSJKlToexz1+fz588WQIUNEcXGx+Pbb\nb8Xf/vY3ERQUJD7//HOVq+6eT4dSZ08//bTQ6/WiublZ6HQ68frrr3dof+2110R8fLxK1TnhJaHU\n2dV93mbfvn0CgNi8ebOKlfmutj6vq6sTer1ebNiw4Zr21NRUlapzzlEoee2cUnfi4+NhtVphNpsx\ncuRIfP/99x3af/jhB0RHR6tUnW+6us/bFBYWYtCgQUhLS1OxMt/V1ueKosBisUCr1XZo12q1sNls\nKlV3g7pLKyH5SOn8+fNi3LhxYuXKleLbb78Vx48fF2vWrBHh4eEiLS1NCCHE+vXrhV6vF8uWLRNH\njx4VhYWFQqfTcU6pl3rS50II0dDQIEJCQsQbb7yhYrW+oSd9PnbsWJGQkCBKS0vF8ePHRVFRkfD3\n9xeLFy9WufruwRdP38xms5g9e7ZISkoSoaGhIiAgQMTGxooXX3xR1NbWtm9XVFQkfvWrXwl/f39x\nxx13iA8//FDFqp2QPJR62ucrVqwQWq1WVFVVqVitb+hJn587d07k5OSIyMhI4e/vL4YOHSrefvtt\nYbPZVK6+e45CSbG3dy0pKUmUl5d7bNTW5ymK/V8H/02IfIGiKBVCiKSu2nxuTomIvBtDiYikwlAi\nIqkwlIhIKgwlIpIKQ4mIpMJQIiKpMJSISCoMJSKSCkOJSBI///wzsrOzMXjwYCQmJiIlJQXr168H\nAGzfvh2jRo1CXFwc4uLiUFhYeM3rhw8fjscff7zDczk5OVi7dq1H6ncVr16jm8hXCCHwyCOPYPLk\nyfjwww8BACdPnkRxcTF++uknZGdnY8OGDRgxYgTOnz+P8ePHw2Qy4cEHHwQAHD58GK2trdi2bRsa\nGhoQFBSk5tu5IRwpEUlgy5YtMBgMmDZtWvtz0dHReO6557B06VLk5ORgxIgRAIB+/fph3rx5mDt3\nbvu2q1evxpNPPon77rsPGzdu9Hj9rsRQIpLAoUOH2kOnq7bExMQOzyUlJeHQoUPtP3/00Ud4/PHH\nkZWVhdWrV7u1VndjKBFJaMaMGfj1r3+NkSNHOt22vLwc/fr1w8CBA5Gamop9+/bhl19+8UCV7sFQ\nIpJAQkIC9u7d2/7z0qVL8eWXX6Kmpgbx8fGoqKjosH1FRQUSEhIA2E/djhw5gpiYGNx22224dOkS\n1q1b59H6XYmhRCSBe++9F2azGe+88077c42NjQDso6Z3330X+/fvBwDU1tbi5ZdfxqxZs2Cz2bBm\nzRocPHgQJ06cwIkTJ7Bx40avPoVjKBFJQFEUbNiwAWVlZRg0aBBGjRqFyZMn46233kJERARWrVqF\nvLw8xMXFYfTo0cjNzUVGRga2bdsGk8mEyMjI9n3dfffdqKysbL9b8dSpUxEVFYWoqCikpKSo9RZ7\njCtPyoQrT1IfwZUnichrMJSISCoMJSKSCkOJiKTCUCIiqTCUiEgqDCUikgpDiYikwlAiIqkwlIhI\nKgwlIpIKQ4mIpMJQIiKpMJSISCoMJSKSCkOJiKTCUCIiqTCUiEgqDCUikgpDiYikwlAiIqkwlIhI\nKgwlIpIKQ4mIpMJQIiKpMJSISCoOb9utKEoNgJOeK4eI+ohoIUT/rhochhIRkafx9I2IpMJQIiKp\nMJSISCoMJSKSCkOJiKTyf0aU9JQt4C07AAAAAElFTkSuQmCC\n","text/plain":["<Figure size 360x360 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Oe40Z1v-qWtA"},"source":["# 9b.2\n","\n","# 파라미터 초깃값 theta_0\n","\n","# 줄은 상태 0~7, 열은 행동방향(상,우,하,좌 순)를 나타낸다.\n","theta_0 = np.array([[np.nan, 1, 1, np.nan],  # s0\n","                    [np.nan, 1, np.nan, 1],  # s1\n","                    [np.nan, np.nan, 1, 1],  # s2\n","                    [1, 1, 1, np.nan],  # s3\n","                    [np.nan, np.nan, 1, 1],  # s4\n","                    [1, np.nan, np.nan, np.nan],  # s5\n","                    [1, np.nan, np.nan, np.nan],  # s6\n","                    [1, 1, np.nan, np.nan],  # s7、※s8은 목표지점이므로 정책이 없다\n","                    ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjS1i128qWtC"},"source":["# 9b.3\n","\n","# 파라미터 theta를 행동 정책 pi로 변환하는 함수\n","# 비율 계산에 소프트맥스 함수 사용\n","def theta_to_pi_softmax(theta):\n","\n","    beta = 1.0\n","    [m, n] = theta.shape  # theta의 행렬 크기를 구함\n","    pi = np.zeros((m, n))\n","\n","    exp_theta = np.exp(beta * theta)  # theta를 exp(theta)로 변환\n","\n","    for i in range(0, m):\n","        # softmax로 계산하는 코드\n","        pi[i, :] = exp_theta[i, :] / np.nansum(exp_theta[i, :])\n","\n","    pi = np.nan_to_num(pi)  # nan을 0으로 변환\n","\n","    return pi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CAmDWIMKqWtE","colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"status":"ok","timestamp":1574682850129,"user_tz":-540,"elapsed":1155,"user":{"displayName":"Eisung Sohn","photoUrl":"","userId":"14422686701909288962"}},"outputId":"a8abdb58-cf89-47a9-df39-f95827f4c608"},"source":["# 9b.4\n","\n","# 초기 정책 pi_0을 계산\n","pi_0 = theta_to_pi_softmax(theta_0)\n","print(pi_0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.         0.5        0.5        0.        ]\n"," [0.         0.5        0.         0.5       ]\n"," [0.         0.         0.5        0.5       ]\n"," [0.33333333 0.33333333 0.33333333 0.        ]\n"," [0.         0.         0.5        0.5       ]\n"," [1.         0.         0.         0.        ]\n"," [1.         0.         0.         0.        ]\n"," [0.5        0.5        0.         0.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AckHZyHFqWtH"},"source":["# 9b.5\n","\n","# 행동 a를 취한 후의 상태 s를 구하는 함수\n","\n","def get_action_and_next_s(pi, s):\n","    direction = [\"up\", \"right\", \"down\", \"left\"]\n","\n","    # pi[s,:]의 확률에 따라 direction 선택\n","    next_direction = np.random.choice(direction, p=pi[s, :])\n","\n","    if next_direction == \"up\":\n","        action = 0\n","        s_next = s - 3  # 위로 이동하면 상태값이 3 줄어든다\n","    elif next_direction == \"right\":\n","        action = 1\n","        s_next = s + 1  # 오른쪽으로 이동하면 상태값이 1 늘어난다\n","    elif next_direction == \"down\":\n","        action = 2\n","        s_next = s + 3  # 아래로 이동하면 상태값이 3 늘어난다\n","    elif next_direction == \"left\":\n","        action = 3\n","        s_next = s - 1  # 왼쪽으로 이동하면 상태값이 1 줄어든다\n","\n","    return [action, s_next]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYvyLFtLqWtJ"},"source":["# 9b.6\n","\n","# 미로를 빠져나오는 함수, 상태와 행동의 히스토리를 반환\n","\n","def goal_maze_ret_s_a(pi):\n","    # Edit this"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2SyK7pvlqWtM","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1574682915122,"user_tz":-540,"elapsed":836,"user":{"displayName":"Eisung Sohn","photoUrl":"","userId":"14422686701909288962"}},"outputId":"9972d73d-97f4-4a50-8b67-1e839972ca4c"},"source":["# 9b.7\n","\n","# 초기 정책으로 미로를 빠져나오기\n","s_a_history = goal_maze_ret_s_a(pi_0)\n","print(s_a_history)\n","print(\"목표 지점까지 {} 단계\".format(str(len(s_a_history) - 1)) )\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0, 1], [1, 1], [2, 3], [1, 3], [0, 1], [1, 3], [0, 1], [1, 1], [2, 2], [5, 0], [2, 2], [5, 0], [2, 2], [5, 0], [2, 2], [5, 0], [2, 2], [5, 0], [2, 3], [1, 3], [0, 1], [1, 3], [0, 2], [3, 0], [0, 1], [1, 1], [2, 2], [5, 0], [2, 2], [5, 0], [2, 2], [5, 0], [2, 3], [1, 1], [2, 3], [1, 3], [0, 2], [3, 0], [0, 1], [1, 1], [2, 2], [5, 0], [2, 2], [5, 0], [2, 3], [1, 1], [2, 3], [1, 3], [0, 2], [3, 0], [0, 1], [1, 3], [0, 2], [3, 2], [6, 0], [3, 2], [6, 0], [3, 1], [4, 2], [7, 1], [8, nan]]\n","목표 지점까지 60 단계\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4d6DGhQWqWtP"},"source":["# 9b.8 \n","\n","# theta를 수정하는 함수\n","\n","def update_theta(theta, pi, s_a_history):\n","    eta = 0.1 # 학습률\n","    T = len(s_a_history) - 1  # 목표 지점에 이르기까지 걸린 단계 수\n","\n","    [m, n] = theta.shape  # theta의 행렬 크기를 구함\n","    delta_theta = theta.copy()  # Δtheta를 구할 준비, 포인터 참조이므로 delta_theta = theta로는 안됨\n","\n","    # delta_theta를 요소 단위로 계산\n","    for i in range(0, m):\n","        for j in range(0, n):\n","            if not(np.isnan(theta[i, j])):  # theta가 nan이 아닌 경우\n","\n","                # Edit this\n","\n","    new_theta = theta + eta * delta_theta\n","\n","    return new_theta"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-rDHv7qYqWtS","colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"status":"ok","timestamp":1574683076111,"user_tz":-540,"elapsed":836,"user":{"displayName":"Eisung Sohn","photoUrl":"","userId":"14422686701909288962"}},"outputId":"cd3c8608-b678-49be-cef7-e9b31b23bd38"},"source":["# 9b.9\n","\n","# 정책 수정\n","new_theta = update_theta(theta_0, pi_0, s_a_history)\n","pi = theta_to_pi_softmax(new_theta)\n","print(pi)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.         0.50125    0.49875    0.        ]\n"," [0.         0.49958333 0.         0.50041667]\n"," [0.         0.         0.50166666 0.49833334]\n"," [0.33388904 0.33277793 0.33333302 0.        ]\n"," [0.         0.         0.50041667 0.49958333]\n"," [1.         0.         0.         0.        ]\n"," [1.         0.         0.         0.        ]\n"," [0.49958333 0.50041667 0.         0.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GxmN_QfKbaex","colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"status":"ok","timestamp":1574683158957,"user_tz":-540,"elapsed":979,"user":{"displayName":"Eisung Sohn","photoUrl":"","userId":"14422686701909288962"}},"outputId":"9a7549c4-c779-41c4-b4d6-722511c27204"},"source":["# 9b.9\n","\n","# 정책 수정\n","new_theta = update_theta(new_theta, pi_0, s_a_history)\n","pi = theta_to_pi_softmax(new_theta)\n","print(pi)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.         0.5124974  0.4875026  0.        ]\n"," [0.         0.49583343 0.         0.50416657]\n"," [0.         0.         0.5166605  0.4833395 ]\n"," [0.33890406 0.32779347 0.33330247 0.        ]\n"," [0.         0.         0.50416657 0.49583343]\n"," [1.         0.         0.         0.        ]\n"," [1.         0.         0.         0.        ]\n"," [0.49583343 0.50416657 0.         0.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RaH1547NqWtX","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1574683247692,"user_tz":-540,"elapsed":1502,"user":{"displayName":"Eisung Sohn","photoUrl":"","userId":"14422686701909288962"}},"outputId":"ecce6777-c4e3-482c-efe6-ca930f9b8557"},"source":["# 9b.10 Edit\n","\n","# 정책 경사 알고리즘으로 미로 빠져나오기\n","\n","stop_epsilon = 10**-4  # 정책의 변화가 10^-4 보다 작아지면 학습을 종료\n","\n","theta = theta_0\n","pi = pi_0\n","\n","is_continue = True\n","count = 1\n","while is_continue:  # is_continue가 False가 될 때까지 반복\n","    \n","    # Edit this\n","    \n","    delta_pi = np.sum(np.abs(new_pi - pi))\n","    total_steps = len(s_a_history) - 1\n","    print(\"정책 변화: {:.5}, 목표 지점까지 {} 단계\".format( delta_pi, total_steps ) )\n","\n","    if np.sum(np.abs(new_pi - pi)) < stop_epsilon:\n","        is_continue = False\n","    else:\n","        theta = new_theta\n","        pi = new_pi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["정책 변화: 0.0271, 목표 지점까지 8 단계\n","정책 변화: 0.014097, 목표 지점까지 14 단계\n","정책 변화: 0.0062604, 목표 지점까지 40 단계\n","정책 변화: 0.015065, 목표 지점까지 26 단계\n","정책 변화: 0.0091753, 목표 지점까지 36 단계\n","정책 변화: 0.016988, 목표 지점까지 10 단계\n","정책 변화: 0.03303, 목표 지점까지 12 단계\n","정책 변화: 0.0057695, 목표 지점까지 142 단계\n","정책 변화: 0.018981, 목표 지점까지 18 단계\n","정책 변화: 0.01174, 목표 지점까지 46 단계\n","정책 변화: 0.016912, 목표 지점까지 46 단계\n","정책 변화: 0.030175, 목표 지점까지 10 단계\n","정책 변화: 0.049464, 목표 지점까지 4 단계\n","정책 변화: 0.0078229, 목표 지점까지 50 단계\n","정책 변화: 0.0070579, 목표 지점까지 60 단계\n","정책 변화: 0.041517, 목표 지점까지 6 단계\n","정책 변화: 0.016169, 목표 지점까지 24 단계\n","정책 변화: 0.0054549, 목표 지점까지 118 단계\n","정책 변화: 0.025026, 목표 지점까지 18 단계\n","정책 변화: 0.0045712, 목표 지점까지 62 단계\n","정책 변화: 0.010127, 목표 지점까지 50 단계\n","정책 변화: 0.0091429, 목표 지점까지 102 단계\n","정책 변화: 0.004793, 목표 지점까지 34 단계\n","정책 변화: 0.011854, 목표 지점까지 90 단계\n","정책 변화: 0.0074731, 목표 지점까지 90 단계\n","정책 변화: 0.026665, 목표 지점까지 10 단계\n","정책 변화: 0.008036, 목표 지점까지 106 단계\n","정책 변화: 0.015423, 목표 지점까지 24 단계\n","정책 변화: 0.017069, 목표 지점까지 30 단계\n","정책 변화: 0.026269, 목표 지점까지 8 단계\n","정책 변화: 0.007306, 목표 지점까지 60 단계\n","정책 변화: 0.0054354, 목표 지점까지 132 단계\n","정책 변화: 0.012906, 목표 지점까지 42 단계\n","정책 변화: 0.019187, 목표 지점까지 24 단계\n","정책 변화: 0.051366, 목표 지점까지 4 단계\n","정책 변화: 0.018553, 목표 지점까지 22 단계\n","정책 변화: 0.0092707, 목표 지점까지 28 단계\n","정책 변화: 0.012163, 목표 지점까지 64 단계\n","정책 변화: 0.032654, 목표 지점까지 8 단계\n","정책 변화: 0.02252, 목표 지점까지 10 단계\n","정책 변화: 0.010548, 목표 지점까지 52 단계\n","정책 변화: 0.013926, 목표 지점까지 24 단계\n","정책 변화: 0.017606, 목표 지점까지 12 단계\n","정책 변화: 0.027862, 목표 지점까지 8 단계\n","정책 변화: 0.024267, 목표 지점까지 14 단계\n","정책 변화: 0.010819, 목표 지점까지 48 단계\n","정책 변화: 0.014862, 목표 지점까지 16 단계\n","정책 변화: 0.0052684, 목표 지점까지 112 단계\n","정책 변화: 0.037225, 목표 지점까지 6 단계\n","정책 변화: 0.053595, 목표 지점까지 4 단계\n","정책 변화: 0.015883, 목표 지점까지 22 단계\n","정책 변화: 0.0064927, 목표 지점까지 92 단계\n","정책 변화: 0.020946, 목표 지점까지 14 단계\n","정책 변화: 0.030854, 목표 지점까지 10 단계\n","정책 변화: 0.029698, 목표 지점까지 14 단계\n","정책 변화: 0.0089879, 목표 지점까지 88 단계\n","정책 변화: 0.012533, 목표 지점까지 56 단계\n","정책 변화: 0.029544, 목표 지점까지 10 단계\n","정책 변화: 0.054962, 목표 지점까지 4 단계\n","정책 변화: 0.023864, 목표 지점까지 16 단계\n","정책 변화: 0.017271, 목표 지점까지 22 단계\n","정책 변화: 0.0093363, 목표 지점까지 38 단계\n","정책 변화: 0.014512, 목표 지점까지 40 단계\n","정책 변화: 0.016184, 목표 지점까지 18 단계\n","정책 변화: 0.0075815, 목표 지점까지 100 단계\n","정책 변화: 0.029565, 목표 지점까지 8 단계\n","정책 변화: 0.03962, 목표 지점까지 6 단계\n","정책 변화: 0.019145, 목표 지점까지 30 단계\n","정책 변화: 0.0079581, 목표 지점까지 34 단계\n","정책 변화: 0.036091, 목표 지점까지 8 단계\n","정책 변화: 0.013335, 목표 지점까지 32 단계\n","정책 변화: 0.012316, 목표 지점까지 60 단계\n","정책 변화: 0.056724, 목표 지점까지 4 단계\n","정책 변화: 0.05716, 목표 지점까지 4 단계\n","정책 변화: 0.014892, 목표 지점까지 42 단계\n","정책 변화: 0.022965, 목표 지점까지 28 단계\n","정책 변화: 0.022007, 목표 지점까지 24 단계\n","정책 변화: 0.057761, 목표 지점까지 4 단계\n","정책 변화: 0.01821, 목표 지점까지 22 단계\n","정책 변화: 0.018773, 목표 지점까지 16 단계\n","정책 변화: 0.010682, 목표 지점까지 42 단계\n","정책 변화: 0.034978, 목표 지점까지 8 단계\n","정책 변화: 0.012587, 목표 지점까지 34 단계\n","정책 변화: 0.058568, 목표 지점까지 4 단계\n","정책 변화: 0.058867, 목표 지점까지 4 단계\n","정책 변화: 0.015785, 목표 지점까지 40 단계\n","정책 변화: 0.016896, 목표 지점까지 22 단계\n","정책 변화: 0.019668, 목표 지점까지 20 단계\n","정책 변화: 0.02747, 목표 지점까지 14 단계\n","정책 변화: 0.028064, 목표 지점까지 10 단계\n","정책 변화: 0.024632, 목표 지점까지 18 단계\n","정책 변화: 0.025473, 목표 지점까지 18 단계\n","정책 변화: 0.030734, 목표 지점까지 12 단계\n","정책 변화: 0.026483, 목표 지점까지 20 단계\n","정책 변화: 0.017386, 목표 지점까지 38 단계\n","정책 변화: 0.020485, 목표 지점까지 30 단계\n","정책 변화: 0.018478, 목표 지점까지 38 단계\n","정책 변화: 0.020433, 목표 지점까지 16 단계\n","정책 변화: 0.060063, 목표 지점까지 4 단계\n","정책 변화: 0.048023, 목표 지점까지 6 단계\n","정책 변화: 0.028275, 목표 지점까지 12 단계\n","정책 변화: 0.027987, 목표 지점까지 12 단계\n","정책 변화: 0.017653, 목표 지점까지 22 단계\n","정책 변화: 0.015931, 목표 지점까지 40 단계\n","정책 변화: 0.060288, 목표 지점까지 4 단계\n","정책 변화: 0.032371, 목표 지점까지 10 단계\n","정책 변화: 0.045773, 목표 지점까지 6 단계\n","정책 변화: 0.012033, 목표 지점까지 80 단계\n","정책 변화: 0.033112, 목표 지점까지 8 단계\n","정책 변화: 0.060088, 목표 지점까지 4 단계\n","정책 변화: 0.032228, 목표 지점까지 12 단계\n","정책 변화: 0.02679, 목표 지점까지 18 단계\n","정책 변화: 0.0395, 목표 지점까지 8 단계\n","정책 변화: 0.059734, 목표 지점까지 4 단계\n","정책 변화: 0.027752, 목표 지점까지 14 단계\n","정책 변화: 0.039404, 목표 지점까지 12 단계\n","정책 변화: 0.047355, 목표 지점까지 6 단계\n","정책 변화: 0.041966, 목표 지점까지 8 단계\n","정책 변화: 0.046001, 목표 지점까지 6 단계\n","정책 변화: 0.034112, 목표 지점까지 12 단계\n","정책 변화: 0.047513, 목표 지점까지 6 단계\n","정책 변화: 0.057867, 목표 지점까지 4 단계\n","정책 변화: 0.024725, 목표 지점까지 22 단계\n","정책 변화: 0.030909, 목표 지점까지 16 단계\n","정책 변화: 0.046082, 목표 지점까지 6 단계\n","정책 변화: 0.056386, 목표 지점까지 4 단계\n","정책 변화: 0.040138, 목표 지점까지 8 단계\n","정책 변화: 0.030331, 목표 지점까지 14 단계\n","정책 변화: 0.042535, 목표 지점까지 6 단계\n","정책 변화: 0.04206, 목표 지점까지 6 단계\n","정책 변화: 0.017336, 목표 지점까지 50 단계\n","정책 변화: 0.033734, 목표 지점까지 8 단계\n","정책 변화: 0.041138, 목표 지점까지 6 단계\n","정책 변화: 0.034325, 목표 지점까지 8 단계\n","정책 변화: 0.052264, 목표 지점까지 4 단계\n","정책 변화: 0.051423, 목표 지점까지 4 단계\n","정책 변화: 0.041628, 목표 지점까지 6 단계\n","정책 변화: 0.049772, 목표 지점까지 4 단계\n","정책 변화: 0.048853, 목표 지점까지 4 단계\n","정책 변화: 0.040574, 목표 지점까지 6 단계\n","정책 변화: 0.047294, 목표 지점까지 4 단계\n","정책 변화: 0.046316, 목표 지점까지 4 단계\n","정책 변화: 0.032965, 목표 지점까지 10 단계\n","정책 변화: 0.044831, 목표 지점까지 4 단계\n","정책 변화: 0.043814, 목표 지점까지 4 단계\n","정책 변화: 0.042785, 목표 지점까지 4 단계\n","정책 변화: 0.036926, 목표 지점까지 6 단계\n","정책 변화: 0.025878, 목표 지점까지 12 단계\n","정책 변화: 0.040411, 목표 지점까지 4 단계\n","정책 변화: 0.030954, 목표 지점까지 6 단계\n","정책 변화: 0.030209, 목표 지점까지 6 단계\n","정책 변화: 0.037674, 목표 지점까지 4 단계\n","정책 변화: 0.028676, 목표 지점까지 6 단계\n","정책 변화: 0.035787, 목표 지점까지 4 단계\n","정책 변화: 0.034746, 목표 지점까지 4 단계\n","정책 변화: 0.027938, 목표 지점까지 6 단계\n","정책 변화: 0.032844, 목표 지점까지 4 단계\n","정책 변화: 0.031828, 목표 지점까지 4 단계\n","정책 변화: 0.030822, 목표 지점까지 4 단계\n","정책 변화: 0.025587, 목표 지점까지 6 단계\n","정책 변화: 0.028997, 목표 지점까지 4 단계\n","정책 변화: 0.02803, 목표 지점까지 4 단계\n","정책 변화: 0.027079, 목표 지점까지 4 단계\n","정책 변화: 0.026144, 목표 지점까지 4 단계\n","정책 변화: 0.025228, 목표 지점까지 4 단계\n","정책 변화: 0.02433, 목표 지점까지 4 단계\n","정책 변화: 0.018534, 목표 지점까지 6 단계\n","정책 변화: 0.022766, 목표 지점까지 4 단계\n","정책 변화: 0.018883, 목표 지점까지 6 단계\n","정책 변화: 0.021221, 목표 지점까지 4 단계\n","정책 변화: 0.020418, 목표 지점까지 4 단계\n","정책 변화: 0.019636, 목표 지점까지 4 단계\n","정책 변화: 0.015661, 목표 지점까지 6 단계\n","정책 변화: 0.018257, 목표 지점까지 4 단계\n","정책 변화: 0.017537, 목표 지점까지 4 단계\n","정책 변화: 0.016838, 목표 지점까지 4 단계\n","정책 변화: 0.016161, 목표 지점까지 4 단계\n","정책 변화: 0.015505, 목표 지점까지 4 단계\n","정책 변화: 0.014871, 목표 지점까지 4 단계\n","정책 변화: 0.014257, 목표 지점까지 4 단계\n","정책 변화: 0.010854, 목표 지점까지 6 단계\n","정책 변화: 0.013207, 목표 지점까지 4 단계\n","정책 변화: 0.012651, 목표 지점까지 4 단계\n","정책 변화: 0.012114, 목표 지점까지 4 단계\n","정책 변화: 0.011597, 목표 지점까지 4 단계\n","정책 변화: 0.011099, 목표 지점까지 4 단계\n","정책 변화: 0.010619, 목표 지점까지 4 단계\n","정책 변화: 0.010157, 목표 지점까지 4 단계\n","정책 변화: 0.0070148, 목표 지점까지 6 단계\n","정책 변화: 0.0081264, 목표 지점까지 6 단계\n","정책 변화: 0.0090476, 목표 지점까지 4 단계\n","정책 변화: 0.008647, 목표 지점까지 4 단계\n","정책 변화: 0.0082624, 목표 지점까지 4 단계\n","정책 변화: 0.0078933, 목표 지점까지 4 단계\n","정책 변화: 0.0075391, 목표 지점까지 4 단계\n","정책 변화: 0.0071996, 목표 지점까지 4 단계\n","정책 변화: 0.0068741, 목표 지점까지 4 단계\n","정책 변화: 0.0065621, 목표 지점까지 4 단계\n","정책 변화: 0.0062633, 목표 지점까지 4 단계\n","정책 변화: 0.0059772, 목표 지점까지 4 단계\n","정책 변화: 0.0057033, 목표 지점까지 4 단계\n","정책 변화: 0.0054411, 목표 지점까지 4 단계\n","정책 변화: 0.0051903, 목표 지점까지 4 단계\n","정책 변화: 0.0049504, 목표 지점까지 4 단계\n","정책 변화: 0.012816, 목표 지점까지 6 단계\n","정책 변화: 0.0045739, 목표 지점까지 4 단계\n","정책 변화: 0.0043611, 목표 지점까지 4 단계\n","정책 변화: 0.0041577, 목표 지점까지 4 단계\n","정책 변화: 0.0039634, 목표 지점까지 4 단계\n","정책 변화: 0.0031302, 목표 지점까지 6 단계\n","정책 변화: 0.0036307, 목표 지점까지 4 단계\n","정책 변화: 0.0034601, 목표 지점까지 4 단계\n","정책 변화: 0.0032972, 목표 지점까지 4 단계\n","정책 변화: 0.0031418, 목표 지점까지 4 단계\n","정책 변화: 0.0029934, 목표 지점까지 4 단계\n","정책 변화: 0.0028518, 목표 지점까지 4 단계\n","정책 변화: 0.0027167, 목표 지점까지 4 단계\n","정책 변화: 0.0025878, 목표 지점까지 4 단계\n","정책 변화: 0.0024649, 목표 지점까지 4 단계\n","정책 변화: 0.0023477, 목표 지점까지 4 단계\n","정책 변화: 0.0022359, 목표 지점까지 4 단계\n","정책 변화: 0.0021293, 목표 지점까지 4 단계\n","정책 변화: 0.0016207, 목표 지점까지 6 단계\n","정책 변화: 0.0019501, 목표 지점까지 4 단계\n","정책 변화: 0.0018569, 목표 지점까지 4 단계\n","정책 변화: 0.001768, 목표 지점까지 4 단계\n","정책 변화: 0.0016833, 목표 지점까지 4 단계\n","정책 변화: 0.0016026, 목표 지점까지 4 단계\n","정책 변화: 0.0015257, 목표 지점까지 4 단계\n","정책 변화: 0.0014524, 목표 지점까지 4 단계\n","정책 변화: 0.0013826, 목표 지점까지 4 단계\n","정책 변화: 0.0013162, 목표 지점까지 4 단계\n","정책 변화: 0.0012528, 목표 지점까지 4 단계\n","정책 변화: 0.0011925, 목표 지점까지 4 단계\n","정책 변화: 0.001135, 목표 지점까지 4 단계\n","정책 변화: 0.0010803, 목표 지점까지 4 단계\n","정책 변화: 0.0010282, 목표 지점까지 4 단계\n","정책 변화: 0.00097855, 목표 지점까지 4 단계\n","정책 변화: 0.00093129, 목표 지점까지 4 단계\n","정책 변화: 0.0008863, 목표 지점까지 4 단계\n","정책 변화: 0.00084346, 목표 지점까지 4 단계\n","정책 변화: 0.00080267, 목표 지점까지 4 단계\n","정책 변화: 0.00076384, 목표 지점까지 4 단계\n","정책 변화: 0.00072687, 목표 지점까지 4 단계\n","정책 변화: 0.00069168, 목표 지점까지 4 단계\n","정책 변화: 0.00065818, 목표 지점까지 4 단계\n","정책 변화: 0.00062629, 목표 지점까지 4 단계\n","정책 변화: 0.00059594, 목표 지점까지 4 단계\n","정책 변화: 0.00056705, 목표 지점까지 4 단계\n","정책 변화: 0.00053955, 목표 지점까지 4 단계\n","정책 변화: 0.00051338, 목표 지점까지 4 단계\n","정책 변화: 0.00048847, 목표 지점까지 4 단계\n","정책 변화: 0.00046476, 목표 지점까지 4 단계\n","정책 변화: 0.0004422, 목표 지점까지 4 단계\n","정책 변화: 0.00042073, 목표 지점까지 4 단계\n","정책 변화: 0.0004003, 목표 지점까지 4 단계\n","정책 변화: 0.00038085, 목표 지점까지 4 단계\n","정책 변화: 0.00036235, 목표 지점까지 4 단계\n","정책 변화: 0.00034474, 목표 지점까지 4 단계\n","정책 변화: 0.00032799, 목표 지점까지 4 단계\n","정책 변화: 0.00031204, 목표 지점까지 4 단계\n","정책 변화: 0.00024529, 목표 지점까지 6 단계\n","정책 변화: 0.00028494, 목표 지점까지 4 단계\n","정책 변화: 0.00027109, 목표 지점까지 4 단계\n","정책 변화: 0.0002579, 목표 지점까지 4 단계\n","정책 변화: 0.00024536, 목표 지점까지 4 단계\n","정책 변화: 0.00023342, 목표 지점까지 4 단계\n","정책 변화: 0.00022206, 목표 지점까지 4 단계\n","정책 변화: 0.00021126, 목표 지점까지 4 단계\n","정책 변화: 0.00020098, 목표 지점까지 4 단계\n","정책 변화: 0.00019119, 목표 지점까지 4 단계\n","정책 변화: 0.00018189, 목표 지점까지 4 단계\n","정책 변화: 0.00017303, 목표 지점까지 4 단계\n","정책 변화: 0.00016461, 목표 지점까지 4 단계\n","정책 변화: 0.00015659, 목표 지점까지 4 단계\n","정책 변화: 0.00014897, 목표 지점까지 4 단계\n","정책 변화: 0.00014171, 목표 지점까지 4 단계\n","정책 변화: 0.00013481, 목표 지점까지 4 단계\n","정책 변화: 0.00012825, 목표 지점까지 4 단계\n","정책 변화: 0.000122, 목표 지점까지 4 단계\n","정책 변화: 0.00011606, 목표 지점까지 4 단계\n","정책 변화: 0.0001104, 목표 지점까지 4 단계\n","정책 변화: 0.00010502, 목표 지점까지 4 단계\n","정책 변화: 9.9908e-05, 목표 지점까지 4 단계\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v5k6PX93qWtb","colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"status":"ok","timestamp":1574683319279,"user_tz":-540,"elapsed":807,"user":{"displayName":"Eisung Sohn","photoUrl":"","userId":"14422686701909288962"}},"outputId":"c520aa86-56bf-444b-9619-5079c5d02dcf"},"source":["# 9b.11\n","\n","# 학습이 끝난 정책을 확인\n","np.set_printoptions(precision=3, suppress=True)  \n","print(pi)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.    0.    1.    0.   ]\n"," [0.    0.386 0.    0.614]\n"," [0.    0.    0.452 0.548]\n"," [0.    1.    0.    0.   ]\n"," [0.    0.    1.    0.   ]\n"," [1.    0.    0.    0.   ]\n"," [1.    0.    0.    0.   ]\n"," [0.    1.    0.    0.   ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nTp21TB4qWtf"},"source":["# 9b.12\n","\n","# 에이전트의 이동 과정을 시각화\n","# 참고 URL http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-notebooks/\n","from matplotlib import animation\n","from IPython.display import HTML\n","\n","\n","def init():\n","    # 배경 이미지 초기화\n","    line.set_data([], [])\n","    return (line,)\n","\n","\n","def animate(i):\n","    # 프레임 단위로 이미지 생성\n","    state = s_a_history[i][0]  # 현재 위치\n","    x = (state % 3) + 0.5  # 상태의 x좌표 : 3으로 나눈 나머지 + 0.5\n","    y = 2.5 - int(state / 3)  # y좌표 : 2.5에서 3으로 나눈 몫을 뺌\n","    line.set_data(x, y)\n","    return (line,)\n","\n","\n","#　초기화 함수와 프레임 단위 이미지 생성한수를 사용하여 애니메이션 생성\n","anim = animation.FuncAnimation(fig, animate, init_func=init, frames=len(\n","    s_a_history), interval=200, repeat=False)\n","\n","HTML(anim.to_jshtml())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_B5DVgZtb0p"},"source":[""],"execution_count":null,"outputs":[]}]}